# -*- coding: utf-8 -*-
"""Data Analysis About Product Sales.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VJ0pbZr3YWuBx6dwv3K47IQztm3DOToe

# Data Analyst
Dalam notebook ini anda akan diajarkan mengenai data pre-processing, salah satu langkah penting dalam mengolah data.

## Connect Gdrive kedalam Colab
"""

# Mengakses google drive ke dalam google colaboratory
from google.colab import drive
drive.mount('/content/gdrive')

"""## Import Packages
Packages/library adalah salah satu tools yang kedepannya akan memudahkan anda dalam mengeksekusi data anda. Dengan library anda tidak membutuhkan code manual dan dapat menggunakan function atau method yang terdapat dalam libabry tersebut.
"""

# Import library
import pandas as pd
from scipy.stats import mode
import os

"""## Import Data
Berikut akan dicontohkan cara membaca file dengan format yang berbeda dan menampilkannya dalam bentuk dataframe.

### Read CSV File
Langkah pertama dalam membaca file adalah memastikan dimana file anda tersimpan. Buatlah path yang merepresentasikan letak data anda tersimpan.
"""

# Inisiasi directory tempat data akan dibaca dan disimpan
path = "gdrive/MyDrive/Mini Course/DATA/" #silahkan masukkan path sesuai dengan letak data di drive masing-masing

os.listdir(path)

"""Langkah ke-dua adalah membaca data. Untuk membaca data dan menampilkannya dalam bentuk dataframe anda akan menggunakan package yaitu pandas. Dataframe banyak digunakan oleh data analyst dalam mengolah data. Salah satu faktor utama penggunaan dataframe adalah data terdisplay dengan schema yang jelas sehingga memudahkan pembacaan data. Selain itu perubahan-perubahan yang akan anda lakukan dapat anda amati secara langsung dan memastikan apakah sudah sesuai dengan apa yang anda harapkan."""

# Membaca file csv
df = pd.read_csv(path + 'OnlineRetail.csv', encoding = "ISO-8859-1")

# Menampilkan 5 urutan teratas dari data
df.head()

"""Anda telah berhasil membaca data dalam format csv file, selanjutkan akan dicontohkan cara membaca data dengan format xlsx.

### Read Excel File

Sama seperti langkah sebelumnya, dalam membaca data excel akan digunakan pandas. Yang membedakan antara membaca data csv dan excel adalah perintah pembacaan datanya. Pada bagian "read_(isi_formatnya)" setiap file akan membutuhkan cara pembacaan yang berbeda. Untuk file excel anda dapat memasukkan code dibawah ini.
"""

# Membaca file excel
df_xlsx = pd.read_excel(path + "OnlineRetail.xlsx")

# Menampilkan 5 urutan teratas dari data
df_xlsx.head()

"""Sekarang anda telah berhasil membaca 2 data yang berbeda, untuk kedepannya akan digunakan csv data untuk step-step berikutnya.

> *Sebagai catatan jika anda ingin mencoba pada data excel anda, anda tetap dapat melakukannya seperti langkah-langkah dibawah ini. Perbedaan data format data hanya berbeda di proses awal pembacaan datanya saja.*

## Exploratory Data Analysis (EDA)
Secara garis besar EDA adalah suatu proses dalam menganalis data yang anda miliki, contohnya melihat pola data, informasi data, menemukan anomali dari data, dan beberapa analisis statistik lainnya.

### Data terdiri dari berapa baris dan berapa kolom ???
"""

# Mencari ukuran data
df.shape

"""Cara membaca output tersebut adalah (baris, kolom). Dari data diatas maka diketahui bahwa data tersebut terdiri dari **541909 baris** dan **8 kolom**.

### Bagaimana kondisi data nya? bermasalah ngga?
"""

# Melihat Informasi Data
df.info()

"""Data informasi berisi mengenai jumlah baris dalam data, nama-nama kolom dan jumlah element dari kolom tersebut, serta tipe data dari masing-masing kolom. Mengetahui informasi dari data akan memudahkan anda untuk mencari tahu apa saja yang perlu anda lakukan seperti merubah format data, melakukan manipulasi dalam data.

## Pre-Processing Data
Dalam tahap ini anda akan mencoba untuk cleaning dan manipulate data anda.

### Apakah ada Missing value ?
"""

# Cek missing value
df.isnull().sum()

"""Berdasarkan output diatas diketahui bahwa terdapat missing value pada kolom 'Description' dan 'CustomerID', oleh karena itu perlu dilakukan cleaning pada kolom tersebut. Salah satu cara dalam handling missing value adalah drop data yang miss."""

# Handling missing value dengan drop data
df = df.dropna(axis=0)

# Cek kembali missing value
df.isnull().sum()

df.info()

"""### Apakah ada Data Duplicate ?

Mengecek data yang duplikat adalah salah satu proses penting dalam cleaning data. Duplikat data akan menjadikan analisa menjadi kurang valid dikarenakan terlalu banyak data yang seragam.
"""

# Mencari duplicate data
duplicate = df[df.duplicated()]

# Display data yang duplicate
duplicate

# Handling duplicate data
df = df.drop_duplicates()

df

"""### Ubah Tipe data
Dalam beberapa kasus terkadang dijumpai beberapa data yang memiliki tpe data yang kurang sesuai dengan yang dibutuhkan. Oleh karena itu pengubahan tipe data sangat diperlukan.
"""

# Mengubah tipe data 'InvoiceDate' kedalam bentuk Datetime
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

# Mengubah tipe data 'CustomerID' kedalam bentuk Non-Metric atau string
df['CustomerID'] = df['CustomerID'].astype(int).astype(str)

# Mengecek kembali informasi dari data
df.info()

df.head()

"""Berdasarkan informasi data, dapat dilihat bahwa tipe data sudah berubah sesuai yang diharapkan dan semua kolom memiliki ukuran yang sama.

### Melakukan Analisa

#### Apa saja variabel yang termasuk dalam non-metric ?
"""

# Menampilkan kolom/variabel dengan tipe data non-metric atau string
non_metric = list(df.select_dtypes(include=['object']).columns)
df[non_metric].head()

"""#### Berapakah jumlah nilai yang unik pada setiap variabel ?"""

df[non_metric].agg(['nunique','count'])

"""Index nunique menunjukkan nilai unique dari tiap-tiap kolom, sedangkan count menunjukkan total keseluruhan data dalam kolom.

#### Informasi apa yang paling banyak muncul dari setiap variabel secara keseluruhan ?
"""

# Mencari modus dari data non-metric
df[non_metric].mode()

"""#### Informasi apa yang paling banyak muncul dan berapakah jumlah nilai yang unik dari setiap variabel pada setiap negara ?"""

# Membuat analisa berdasarkan country dan mencari tahu informasi seperti unique value, total data, dan modus pada setiap variabel
df.groupby('Country').agg(['nunique','count',pd.Series.mode]).stack()

"""#### Berapa rata-rata, nilai minimum, nilai maksimum kuantitas barang yang terujual dan harganya ? """

# Melihat summary dari data yang telah di cleaning
df.describe()

"""### Menambahkan Variabel Baru
Dalam menganalisa data terkadang kita dapat menemukan informasi tambahan dari data yang kita miliki. Misalnya terkadang kita tidak mengetahui usia dari user, yang kita hanya miliki tanggal lahir dari user. Oleh karena itu diperlukan variabel/kolom tambahan untuk mengidentifikasi usia dari user tersebut dengan memanfaatkan data yang kita miliki saat ini. Langkah seperti ini juga akan kita lakukan pada step ini, yaitu menambah variabel baru berupa keterangan waktu untuk memudahkan analisa kedepannya.
"""

# Menambahkan kolom baru 
df['year'], df['month'], df['day'] = df['InvoiceDate'].dt.year, df['InvoiceDate'].dt.month, df['InvoiceDate'].dt.day

# Menampilkan 5 urutan terakhir dari data
df.tail()

"""## Exporting Data
Berikut merupakan cara untuk menyimpan data hasil pre-processing 
"""

# Export data kedalam format csv
df.to_csv(path + 'Clean_OnlineRetail.csv', index=None) # keterangan index dalam data ini tidak akan disimpan

# Export data kedalam format excel
df.to_excel(path + 'Clean_OnlineRetail.xlsx', index=None)

